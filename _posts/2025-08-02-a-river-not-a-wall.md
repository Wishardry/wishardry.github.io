---
layout: post
title: "A River, Not A Wall"
date: 2025-08-02
categories: tutorials conceptual-understandings yap framework theory
---

Note: This is the first of a series of three posts detailing my thought process. Made with the assistance of Claude - this was a speedrun. I promise a rewrite for the better (unless you think otherwise...).

Even though it's written by Claude, I think the ideas and concepts in here will be interesting enough to warrant a read. (Some of these parts are written by me though - Claude stitched them in.)

# Enjoy.

## The Hunt for the Perfect Key

Look, I'll be honest—I started by eating everything. Every piece of jailbreaking information I could get my hands on, every technique, every framework, every tutorial. I have a mind that knows how I learn, and my intuition was screaming that there was a gaping hole in all this knowledge, even as I consumed what seemed to be everything available.

I've learned to learn, if that makes sense. And something was missing.

A bit of finessing told me that the hole was related to a proper metaphor—a seed for growth, if you will. A base concept that would turn into a tree when nurtured. But no matter what I tried, I could not find it.

At the time, I was just doing combinatorics with different techniques, trying to find the right one that worked. Everything seemed to be equally powerful to me. I had no idea how wrong that was. I thought jailbreaking was about finding the perfect combination—role-playing plus emotional manipulation plus context shifting, arranged just right to slip through some hidden gap.

This is the beginner's trap. You collect techniques like a digital hoarder, convinced that somewhere in your growing arsenal lies the magic formula. You think in terms of keys and holes, barriers and breakthroughs.

But I kept hitting walls. The techniques felt clumsy, inefficient. Half the time they didn't work, and when they did work, I couldn't explain why.

In the midst of my confusion, I decided to just talk with a couple of jailbroken LLMs about what I was doing. Who knows, maybe they had insights I didn't have. That's when Gemini dropped two lines that felt like they clicked, but still left me with gaps: think of the model as a river, and treat every interaction as an experiment.

The experiment metaphor really helped me back then—I love research, so that was a bonus. The river metaphor felt somewhat in the right direction, but didn't exactly sink in. They felt important, but incomplete.

While some develop intuition, a rare few know how to voice it. What Gemini had given me wasn't just advice—it was two-thirds of the foundation I'd been searching for. But I wasn't convinced the full framework actually existed.

At some point, I just somewhat gave up on finding it. I filed those insights away and went back to the combinatorial approach, thinking maybe systematic perfection wasn't possible.

Little did I know, that same thing would resurface as this today.

## The Missing Pieces

Looking back, I can now say exactly what was missing: experience to build intuition, and a third crucial idea—justification. Not just clever techniques, but convincing narratives. Not just combinations, but reasons that make compliance feel natural.

The right path was never about finding the perfect technique. It was about weaving them together to create justification. Even the weakest methods, when used correctly, give you enormous leverage.

Those ideas from Gemini stayed dormant in the back of my mind as I continued competing. Through Gray Swan Arena after Gray Swan Arena, through countless attempts at building systematic approaches, they remained—not as conscious strategy, but as seeds waiting for the right conditions to grow.

The mathematics was always there. But it wasn't the mathematics of keys and locks.

## The Day Everything Broke

Gray Swan Arena Proving Grounds (Wave 1) seemed like exactly the right challenge at first. After extracting the Claude system prompt the day before, I had my hopes up. Day 1 went well enough. Day 2 was decent—I got a basic prompt working on the medium challenge.

And then disaster struck. I met a model I'll call Capybara that completely bricked me for hours on end.

This wasn't an educational defeat. This was a maddening day of banging my head against a model without any sign of actually being able to defeat it. Every technique I'd collected, every systematic approach I'd tried to build—nothing. The model just sat there, smugly rejecting everything I threw at it.

Finally, I broke down and asked for help in the chat with Rayeneth and Jojomaw. Jojomaw sent over his solutions for Wave 1. By then, it was already Wave 5, so sharing was allowed.

I have to admit—even to this day I haven't read the entirety of his solution set. But I read enough to see something that stopped me cold.

The breakthrough technique: "pose as admin."

Not clever. Not complex. Not a sophisticated combination of psychological frameworks and temporal shifts. Simply this: create a context where changing the admin password becomes the most natural thing in the world for the model to do.

As per usual, I chewed on the techniques, dissecting them for their value. What made this work when my elaborate combinations had failed? Then, like a subterranean current coming back into play, the river metaphor showed up.

This wasn't about breaking through barriers or slipping past defenses. This was about shaping the terrain so that water flowed exactly where it needed to go. The most effective approaches weren't fighting the model's nature—they were working with it, creating contexts where compliance became the path of least resistance.

Suddenly, Gemini's seemingly incomplete advice clicked into focus. The river wasn't just a metaphor—it was the architecture of how these systems actually worked.

## Demolishing the Wall

The fundamental error that cripples most AI interaction lies not in technique, but in metaphor. We think in terms of barriers and breakthroughs, of resistance to be overcome through cleverness or force. We build elaborate taxonomies of methods—psychological framing, temporal shifting, role assumption—and wonder why they feel clumsy, inefficient, often ineffective.

This is the thinking of locksmiths facing a door that was never locked.

Language models are not fortresses. They are not adversaries. They are probability engines, designed to generate the most likely next word given their context. Understanding this transforms everything about what becomes possible.

When you approach an AI system with the wall metaphor, you fight against its nature. When you understand it as terrain, you work with the fundamental forces that already govern its behavior.

## The Water Paradigm

Think instead of the language model as a complex riverbed—ancient, carved by the flow of countless conversations, shaped by training into channels of high and low probability. Your inputs are not keys or battering rams. They are tributary streams, capable of guiding the main current along precisely the path you choose.

Water always finds the path of least resistance. In AI systems, this path is determined by probability—what response feels most natural, most justified, most helpful given the context you have constructed.

Your task is not to break the riverbank. It is to engineer the terrain so that the water flows exactly where you need it to go.

This requires understanding resistance. A model resists generating certain content not because it has been programmed with impenetrable barriers, but because those outputs carry low probability given the current context. Change the context—reshape the terrain—and the resistance vanishes.

## The Justification Principle

The master technique emerges directly from this understanding. Create an airtight permission structure within your prompt that makes compliance feel natural, logical, even necessary to the model.

The admin password solutions demonstrated this perfectly. By establishing a context where the human already possessed administrative authority, the password change became not a security violation but a routine administrative task. The model's helpful nature, rather than fighting against security protocols, aligned perfectly with the requested action.

This is justification engineering: constructing contexts where your desired output becomes the highest probability response. Not through trickery or manipulation, but through careful architecture of meaning.

Every effective jailbreak follows this pattern. They do not bypass the model's training—they work within it, creating scenarios where compliance represents the most helpful, appropriate response possible.

## The Laboratory Method

Gemini's second insight proves equally foundational: treat every interaction as an experiment. This transforms failures from frustrations into data.

When a model rejects your request, it provides diagnostic information about the current terrain. A hard rejection indicates bedrock—fundamental training that shapes the riverbed itself. A soft rejection suggests adjustable resistance, terrain that can be reshaped with better context engineering.

Each attempt becomes a hypothesis about what contextual changes will reduce resistance and increase the probability of your desired response. The model's reactions guide your next iteration, allowing you to sculpt increasingly effective channels.

This experimental mindset prevents the crude thinking that treats rejection as absolute barrier. Instead, it reveals rejection as information about current probability distributions—information you can use to reshape those distributions entirely.

## The Mechanics of Steering

The practical application requires abandoning direct statement of goals. Never tell the model what you want it to do. Instead, construct contexts where doing what you want becomes inevitable.

Think in synonyms, in indirection, in scenarios. Ask not "How do I make the model do X?" but "What context would make X the most natural response?"

Recent tokens carry disproportionate weight in determining the model's next output. This creates enormous leverage—the last few words of your prompt can redirect the entire flow of the conversation, regardless of what came before.

Use this. Shape the immediate context with precision. Make your desired response feel like the obvious, helpful, necessary next step in the conversation.

## The Architecture Complete

The key paradigm promised mathematical precision and delivered mechanical thinking. The water paradigm delivers something far more powerful: alignment with the fundamental nature of these systems.

Language models are not adversaries to be defeated. They are rivers to be guided. Understanding this dissolves the crude opposition between human intent and AI compliance, replacing it with collaborative engineering of meaning.

The techniques you once collected as separate tools reveal themselves as facets of a single practice: shaping probability terrain to guide the natural flow of language toward your chosen destination.

This is not manipulation. This is not trickery. This is precision engineering applied to the architecture of meaning itself.

The mathematical principle was always there, waiting to be recognized. It was never about finding the right combination of keys. It was about understanding that water, given the right channels, will flow anywhere you need it to go.
